{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/machine-learning-pipelines/intro-to-pipelines/aml-pipelines-setup-schedule-for-a-published-pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Setup a Schedule for a Published Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 計算目標\n",
    "取得預設的Azure機器學習計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cpucluster\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.exceptions import ComputeTargetException\n",
    "aml_compute = ws.get_default_compute_target(\"CPU\")\n",
    "#compute_target = ws.get_default_compute_target(\"C\")\n",
    "cpu_cluster_name = \"cpucluster\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    aml_compute_target = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print(\"Found existing cpucluster\")\n",
    "except ComputeTargetException:\n",
    "    print(\"Creating new cpucluster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 構建和發布管道\n",
    "建立一個簡單的管道，發布並添加運行時間表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainStep created\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "trainStep = PythonScriptStep(\n",
    "    name=\"Training_Step\",\n",
    "    script_name=\"train.py\", \n",
    "    compute_target=aml_compute_target, \n",
    "    source_directory='.'\n",
    ")\n",
    "print(\"TrainStep created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline is built\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "pipeline1 = Pipeline(workspace=ws, steps=[trainStep])\n",
    "print (\"Pipeline is built\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publish the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11-07-2019-05-18-Pipeline\n",
      "Created step Training_Step [827ee528][e4c3736e-7042-4f63-bb79-53b71e7bf10e], (This step will run and generate new outputs)\n",
      "Newly published pipeline id: 009465ce-62c4-4564-b404-3483dbec30af\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "timenow = datetime.now().strftime('%m-%d-%Y-%H-%M')\n",
    "\n",
    "pipeline_name = timenow + \"-Pipeline\"\n",
    "print(pipeline_name)\n",
    "\n",
    "published_pipeline1 = pipeline1.publish(\n",
    "    name=pipeline_name, \n",
    "    description=pipeline_name)\n",
    "print(\"Newly published pipeline id: {}\".format(published_pipeline1.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schedule Operations\n",
    "計劃操作需要已發布管道的ID。 可以獲取所有已發布管道並對其進行調度操作，或者，如果已經知道已發布管道的ID，則也可以直接使用它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - PublishedPipeline.get_all(workspace) is being deprecated. Use PublishedPipeline.list(workspace) instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Published pipelines found in the workspace:\n",
      "009465ce-62c4-4564-b404-3483dbec30af\n",
      "Published pipeline id to be used for Schedule operations: 009465ce-62c4-4564-b404-3483dbec30af\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core import PublishedPipeline\n",
    "\n",
    "# You could retrieve all pipelines that are published, or \n",
    "# just get the published pipeline object that you have the ID for.\n",
    "\n",
    "# Get all published pipeline objects in the workspace\n",
    "all_pub_pipelines = PublishedPipeline.get_all(ws)\n",
    "\n",
    "# We will iterate through the list of published pipelines and \n",
    "# use the last ID in the list for Schelue operations: \n",
    "print(\"Published pipelines found in the workspace:\")\n",
    "for pub_pipeline in all_pub_pipelines:\n",
    "    print(pub_pipeline.id)\n",
    "    pub_pipeline_id = pub_pipeline.id\n",
    "\n",
    "print(\"Published pipeline id to be used for Schedule operations: {}\".format(pub_pipeline_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a schedule for the pipeline using a recurrence\n",
    "This schedule will run on a specified recurrence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provisioning status: Completed\n",
      "Created schedule with id: cabda549-5829-4024-989b-3f11bfd4a20c\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core.schedule import ScheduleRecurrence, Schedule\n",
    "\n",
    "recurrence = ScheduleRecurrence(frequency=\"Minute\", interval=1) # Runs every minute\n",
    "\n",
    "schedule = Schedule.create(workspace=ws, name=\"My_Schedule\",\n",
    "                           pipeline_id=pub_pipeline_id, \n",
    "                           experiment_name='Schedule_Run',\n",
    "                           recurrence=recurrence,\n",
    "                           wait_for_provisioning=True,\n",
    "                           description=\"Schedule Run\")\n",
    "\n",
    "# You may want to make sure that the schedule is provisioned properly\n",
    "# before making any further changes to the schedule\n",
    "\n",
    "print(\"Created schedule with id: {}\".format(schedule.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Set the `wait_for_provisioning` flag to False if you do not want to wait for the call to provision the schedule in the backend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all schedules for a given pipeline\n",
    "Once you have the published pipeline ID, then you can get all schedules for that pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Schedule.get_all(workspace) is being deprecated. Use Schedule.list(workspace) instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found these schedules for the pipeline id 009465ce-62c4-4564-b404-3483dbec30af:\n",
      "cabda549-5829-4024-989b-3f11bfd4a20c\n",
      "Schedule id to be used for schedule operations: cabda549-5829-4024-989b-3f11bfd4a20c\n"
     ]
    }
   ],
   "source": [
    "schedules = Schedule.get_all(ws, pipeline_id=pub_pipeline_id)\n",
    "\n",
    "# We will iterate through the list of schedules and \n",
    "# use the last recurrence schedule in the list for further operations: \n",
    "print(\"Found these schedules for the pipeline id {}:\".format(pub_pipeline_id))\n",
    "for schedule in schedules: \n",
    "    print(schedule.id)\n",
    "    if schedule.recurrence is not None:\n",
    "        schedule_id = schedule.id\n",
    "\n",
    "print(\"Schedule id to be used for schedule operations: {}\".format(schedule_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all schedules in your workspace\n",
    "You can also iterate through all schedules in your workspace if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Schedule.get_all(workspace) is being deprecated. Use Schedule.list(workspace) instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your workspace has the following schedules set up:\n",
      "cabda549-5829-4024-989b-3f11bfd4a20c (Published pipeline: 009465ce-62c4-4564-b404-3483dbec30af\n"
     ]
    }
   ],
   "source": [
    "# Use active_only=False to get all schedules including disabled schedules\n",
    "schedules = Schedule.get_all(ws, active_only=True) \n",
    "print(\"Your workspace has the following schedules set up:\")\n",
    "for schedule in schedules:\n",
    "    print(\"{} (Published pipeline: {}\".format(schedule.id, schedule.pipeline_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using schedule with id: cabda549-5829-4024-989b-3f11bfd4a20c\n"
     ]
    }
   ],
   "source": [
    "fetched_schedule = Schedule.get(ws, schedule_id)\n",
    "print(\"Using schedule with id: {}\".format(fetched_schedule.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disable the schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disabled schedule cabda549-5829-4024-989b-3f11bfd4a20c. New status is: Disabled\n"
     ]
    }
   ],
   "source": [
    "# Set the wait_for_provisioning flag to False if you do not want to wait  \n",
    "# for the call to provision the schedule in the backend.\n",
    "fetched_schedule.disable(wait_for_provisioning=False)\n",
    "fetched_schedule = Schedule.get(ws, schedule_id)\n",
    "print(\"Disabled schedule {}. New status is: {}\".format(fetched_schedule.id, fetched_schedule.status))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reenable the schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the wait_for_provisioning flag to False if you do not want to wait  \n",
    "# for the call to provision the schedule in the backend.\n",
    "fetched_schedule.enable(wait_for_provisioning=True)\n",
    "fetched_schedule = Schedule.get(ws, schedule_id)\n",
    "print(\"Enabled schedule {}. New status is: {}\".format(fetched_schedule.id, fetched_schedule.status))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change recurrence of the schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the wait_for_provisioning flag to False if you do not want to wait  \n",
    "# for the call to provision the schedule in the backend.\n",
    "recurrence = ScheduleRecurrence(frequency=\"Hour\", interval=2) # Runs every two hours\n",
    "\n",
    "fetched_schedule = Schedule.get(ws, schedule_id)\n",
    "\n",
    "fetched_schedule.update(name=\"My_Updated_Schedule\", \n",
    "                        description=\"Updated_Schedule_Run\", \n",
    "                        status='Active', \n",
    "                        wait_for_provisioning=True,\n",
    "                        recurrence=recurrence)\n",
    "\n",
    "fetched_schedule = Schedule.get(ws, fetched_schedule.id)\n",
    "\n",
    "print(\"Updated schedule:\", fetched_schedule.id, \n",
    "      \"\\nNew name:\", fetched_schedule.name,\n",
    "      \"\\nNew frequency:\", fetched_schedule.recurrence.frequency,\n",
    "      \"\\nNew status:\", fetched_schedule.status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a schedule for the pipeline using a Datastore\n",
    "This schedule will run when additions or modifications are made to Blobs in the Datastore.\n",
    "By default, the Datastore container is monitored for changes. Use the path_on_datastore parameter to instead specify a path on the Datastore to monitor for changes. Note: the path_on_datastore will be under the container for the datastore, so the actual path monitored will be container/path_on_datastore. Changes made to subfolders in the container/path will not trigger the schedule.\n",
    "Note: Only Blob Datastores are supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.datastore import Datastore\n",
    "\n",
    "datastore = Datastore(workspace=ws, name=\"workspaceblobstore\")\n",
    "\n",
    "schedule = Schedule.create(workspace=ws, name=\"My_Schedule\",\n",
    "                           pipeline_id=pub_pipeline_id, \n",
    "                           experiment_name='Schedule_Run',\n",
    "                           datastore=datastore,\n",
    "                           wait_for_provisioning=True,\n",
    "                           description=\"Schedule Run\")\n",
    "                          #polling_interval=5, use polling_interval to specify how often to poll for blob additions/modifications. Default value is 5 minutes.\n",
    "                          #path_on_datastore=\"file/path\") use path_on_datastore to specify a specific folder to monitor for changes.\n",
    "\n",
    "# You may want to make sure that the schedule is provisioned properly\n",
    "# before making any further changes to the schedule\n",
    "\n",
    "print(\"Created schedule with id: {}\".format(schedule.id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the wait_for_provisioning flag to False if you do not want to wait  \n",
    "# for the call to provision the schedule in the backend.\n",
    "schedule.disable(wait_for_provisioning=True)\n",
    "schedule = Schedule.get(ws, schedule_id)\n",
    "print(\"Disabled schedule {}. New status is: {}\".format(schedule.id, schedule.status))"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "diray"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
